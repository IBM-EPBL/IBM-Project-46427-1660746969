{"cells":[{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'/home/wsuser/work'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","import os, types\n","import pandas as pd\n","from botocore.client import Config\n","import ibm_boto3\n","\n","def __iter__(self): return 0\n","\n","# @hidden_cell\n","# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n","# You might want to remove those credentials before you share the notebook.\n","cos_client = ibm_boto3.client(service_name='s3',\n","    ibm_api_key_id='GFFkMBWO15paKH1O1jX4GD_J32x0XfF7z9K6c_AH0OWX',\n","    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n","    config=Config(signature_version='oauth'),\n","    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n","\n","bucket = 'imageclassification-donotdelete-pr-kexaouraezeh26'\n","object_key = 'Training-20221112T024940Z-001.zip'\n","\n","streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n","\n","# Your data file was loaded into a botocore.response.StreamingBody object.\n","# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n","# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n","# pandas documentation: http://pandas.pydata.org/\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'streaming_body_1' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn [1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m BytesIO\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzipfile\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m unzip\u001b[39m=\u001b[39mzipfile\u001b[39m.\u001b[39mZipFile(BytesIO(streaming_body_1\u001b[39m.\u001b[39mread()),\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m file_paths\u001b[39m=\u001b[39munzip\u001b[39m.\u001b[39mnamelist()\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m file_paths:\n","\u001b[1;31mNameError\u001b[0m: name 'streaming_body_1' is not defined"]}],"source":["from io import BytesIO\n","import zipfile\n","unzip=zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n","file_paths=unzip.namelist()\n","for path in file_paths:\n","    unzip.extract(path)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["nutrition-classification-model.tgz  \u001b[0m\u001b[01;34mTraining\u001b[0m/\r\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["'/home/wsuser/work'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"egoZTFV76iVX"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-18 09:30:35.148460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ibm/dsdriver/lib:/opt/oracle/lib:/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow\n"]}],"source":["from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np#used for numerical analysis\n","import tensorflow #open source used for both ML and DL for computation\n","from tensorflow.keras.models import Sequential #it is a plain stack of Layers\n","from tensorflow.keras import layers #A Layer consists of a tensor-in tensor-out computation function\n","#Dense Layer is the regular deeply connected neural network Layer\n","from tensorflow.keras.layers import Dense, Flatten\n","#Faltten-used fot flattening the input or change the dimension\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout #Convolutional layer\n","#MaxPooling2D-for downsampling the image\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2d-qHO1a6s1v"},"outputs":[],"source":["train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n","test_datagen=ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dKK9jMzi60kh","outputId":"9a203c8b-fca2-4b67-fcc7-0181006ceb7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4138 images belonging to 5 classes.\n","Found 4138 images belonging to 5 classes.\n"]}],"source":["x_train = train_datagen.flow_from_directory(\n","    r'/home/wsuser/work/Training/Dataset/TRAIN_SET',\n","    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n","x_test = test_datagen.flow_from_directory(\n","    r'/home/wsuser/work/Training/Dataset/TRAIN_SET',\n","    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse') "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlAvN06zZhRa","outputId":"bb6d0aca-89f1-4966-efda-a65d0651ea25"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"]}],"source":["print(x_train.class_indices)#checking the number of classes"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81FY2m7A_oPi","outputId":"ba205914-5b7e-41e9-db58-e1416afee38f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"]}],"source":["print(x_test.class_indices) #checking the number of classes"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxn_rBQ3_rTq","outputId":"7a06f3bf-5fe5-475b-e4f5-c6372215b549"},"outputs":[{"data":{"text/plain":["Counter({0: 995, 1: 1374, 2: 1019, 3: 275, 4: 475})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["from collections import Counter as c \n","c(x_train .labels)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qv92cae5URJ5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-18 09:30:43.542112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ibm/dsdriver/lib:/opt/oracle/lib:/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow\n","2022-11-18 09:30:43.542203: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n"]}],"source":["model=Sequential()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"O0kAvbMNURJ5"},"outputs":[],"source":["# Initializing the CNN classifier = Sequential()\n","classifier = Sequential()\n","# First convolution layer and pooling\n","classifier.add(Conv2D(32,(3, 3), input_shape=(64, 64, 3),activation='relu')) \n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","# Second convolution layer and pooling\n","classifier.add(Conv2D(32, (3, 3), activation='relu'))\n","# input_shape is going to be the pooled feature maps from the previous convolution layer \n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","# Flattening the Layers\n","classifier.add(Flatten())\n","# Adding fully connected Layer a\n","classifier.add(Dense (units=128, activation='relu'))\n","classifier.add(Dense (units=5, activation='softmax')) # softmax for more than 2"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d08Oruh01Kz3","outputId":"1c496370-d1be-4030-abde-26cca6c89931"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 62, 62, 32)        896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 6272)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               802944    \n","                                                                 \n"," dense_1 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 813,733\n","Trainable params: 813,733\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["classifier.summary()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"vn-AEp2bURJ7"},"outputs":[],"source":["classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3RcBQmG-OVP","outputId":"2c6a92de-e768-4cf3-b484-479a0a269c5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/wsuser/ipykernel_1592/2706448856.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  classifier.fit_generator(\n"]},{"name":"stdout","output_type":"stream","text":["828/828 [==============================] - 59s 70ms/step - loss: 0.6154 - accuracy: 0.7637 - val_loss: 0.5561 - val_accuracy: 0.8057\n","Epoch 2/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.4144 - accuracy: 0.8538 - val_loss: 0.3022 - val_accuracy: 0.8792\n","Epoch 3/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.3773 - accuracy: 0.8610 - val_loss: 0.4107 - val_accuracy: 0.8473\n","Epoch 4/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.3587 - accuracy: 0.8673 - val_loss: 0.3196 - val_accuracy: 0.8736\n","Epoch 5/20\n","828/828 [==============================] - 58s 69ms/step - loss: 0.3257 - accuracy: 0.8758 - val_loss: 0.2663 - val_accuracy: 0.9072\n","Epoch 6/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.3078 - accuracy: 0.8847 - val_loss: 0.2331 - val_accuracy: 0.9203\n","Epoch 7/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.2899 - accuracy: 0.8917 - val_loss: 0.3402 - val_accuracy: 0.8731\n","Epoch 8/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.2819 - accuracy: 0.8896 - val_loss: 0.2249 - val_accuracy: 0.9183\n","Epoch 9/20\n","828/828 [==============================] - 58s 69ms/step - loss: 0.2508 - accuracy: 0.9053 - val_loss: 0.1993 - val_accuracy: 0.9181\n","Epoch 10/20\n","828/828 [==============================] - 58s 69ms/step - loss: 0.2372 - accuracy: 0.9072 - val_loss: 0.2150 - val_accuracy: 0.9190\n","Epoch 11/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.2318 - accuracy: 0.9108 - val_loss: 0.2696 - val_accuracy: 0.8973\n","Epoch 12/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.2274 - accuracy: 0.9149 - val_loss: 0.2333 - val_accuracy: 0.9128\n","Epoch 13/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.2040 - accuracy: 0.9246 - val_loss: 0.1951 - val_accuracy: 0.9248\n","Epoch 14/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.1913 - accuracy: 0.9314 - val_loss: 0.1529 - val_accuracy: 0.9512\n","Epoch 15/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.1790 - accuracy: 0.9389 - val_loss: 0.2946 - val_accuracy: 0.8915\n","Epoch 16/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.1912 - val_accuracy: 0.9256\n","Epoch 17/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.1520 - accuracy: 0.9444 - val_loss: 0.0877 - val_accuracy: 0.9691\n","Epoch 18/20\n","828/828 [==============================] - 58s 70ms/step - loss: 0.1505 - accuracy: 0.9435 - val_loss: 0.1040 - val_accuracy: 0.9580\n","Epoch 19/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.1481 - accuracy: 0.9468 - val_loss: 0.1026 - val_accuracy: 0.9647\n","Epoch 20/20\n","828/828 [==============================] - 57s 69ms/step - loss: 0.1345 - accuracy: 0.9483 - val_loss: 0.0883 - val_accuracy: 0.9693\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fd37ee5b4f0>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["##Fitting the model\n","classifier.fit_generator(\n","    generator=x_train,steps_per_epoch = len(x_train), \n","    epochs=20,validation_data=x_test,validation_steps = len(x_test)) # No of images in test set\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["nutrition-classification-model.tgz  \u001b[0m\u001b[01;34mTraining\u001b[0m/\r\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"1F119invVdKS"},"outputs":[],"source":["classifier.save('nutrition.h5')"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["nutrition-classification-model.tgz  nutrition.h5  \u001b[0m\u001b[01;34mTraining\u001b[0m/\r\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["'/home/wsuser/work'"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"h0E4XsFFURJ9"},"outputs":[],"source":["### Predicting our results\n","from tensorflow.keras.models import load_model\n","from keras.preprocessing import image\n","model = load_model(\"nutrition.h5\") #Loading the model for testing\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPxmrSndaH6J","outputId":"b386a249-454d-4c7b-e7c4-65c4a3972671"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/home/wsuser/work/Training/Dataset/TRAIN_SET/ORANGE/100_100.jpg'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/wsuser/ipykernel_1592/348761095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/home/wsuser/work/Training/Dataset/TRAIN_SET/ORANGE/100_100.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#image to array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#changing the shape =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'APPLES'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BANANA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ORANGE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PINEAPPLE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'WATERMELON'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/wsuser/work/Training/Dataset/TRAIN_SET/ORANGE/100_100.jpg'"]}],"source":["img =image.load_img(r\"/home/wsuser/work/Training/Dataset/TRAIN_SET/ORANGE/100_100.jpg\",grayscale=False, target_size= (64,64))\n","x = image.img_to_array(img)#image to array\n","x = np.expand_dims(x,axis=0) #changing the shape =\n","y =np.argmax(model.predict(x),axis=1)\n","index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n","index[y[0]]"]},{"cell_type":"markdown","metadata":{},"source":["# IBM Deployment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install watson-machine-learning-client"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install keras==2.2.4\n","!pip install tensorflow==2.5.0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning import APIClient\n","wml_credentials={\n","    \"url\":\"https://us-south.ml.cloud.ibm.com\",\n","    \"apikey\":\"8jr_3j3cMpvuPq0YklClRwbLiNipMBpeDj98fB_xkqHi\"\n","}\n","\n","client=APIClient(wml_credentials)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def guid_space_name(client,nutrition_deploy):\n","    space=client.spaces.get_details()\n","    return(next(item for item in space['resources'] if item['entity']['name']==nutrition_deploy)['metadata']['id'])"]},{"cell_type":"markdown","metadata":{},"source":["# Deployment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["space_uid=guid_space_name(client,'nutrition_deploy')\n","print(\"Space UID \" + space_uid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.set.default_space(space_uid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.software_specifications.list(200)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["software_space_uid"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!tar -zcvf nutrition-classification-model.tgz nutrition.h5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_details=client.repository.store_model(model ='nutrition-classification-model.tgz', meta_props={\n","    client.repository.ModelMetaNames.NAME: \"CNN Model Building\",\n","    client.repository.ModelMetaNames.TYPE: 'tensorflow_2.7',\n","    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_space_uid\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_id = client.repository.get_model_id(model_details)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.repository.download(model_id,'nutrition.tar.gb')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pwd"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":1}
